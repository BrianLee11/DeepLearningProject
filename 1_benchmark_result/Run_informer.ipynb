{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Zhou's mdoel: Informer application on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdaIHYx4_ECL"
   },
   "source": [
    "## Download code and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SA_i2gbl-rn-",
    "outputId": "ee8c6613-ed4c-4514-ea7a-36960ccb30f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Informer2020' already exists and is not an empty directory.\n",
      "fatal: destination path 'ETDataset' already exists and is not an empty directory.\n",
      "ETDataset  Informer2020  sample_data\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zhouhaoyi/Informer2020\n",
    "!git clone https://github.com/zhouhaoyi/ETDataset.git\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if not 'Informer2020' in sys.path:\n",
    "    sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YW9TS6jp_YXc"
   },
   "outputs": [],
   "source": [
    "# !pip install -r ./Informer2020/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XtjMDnYimSQ",
    "outputId": "f20d101c-f2de-404b-ed2e-c405c9408da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6mx2dnwY9dWi"
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'ETTh1' # data\n",
    "args.root_path = '/content/drive/MyDrive/DeepLearning/' # root path of data file\n",
    "args.data_path = 'filtered_data_without_index.csv' # data file\n",
    "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'OT' # target feature in S or MS task\n",
    "args.freq = 'h' # freq for time features encoding, options:\n",
    "# [s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 96     # input sequence length of Informer encoder\n",
    "args.label_len = 48   # start token length of Informer decoder\n",
    "args.pred_len = 45*24    # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 10 # encoder input size\n",
    "args.dec_in = 10 # decoder input size\n",
    "args.c_out = 10 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.freq = 'h'\n",
    "\n",
    "args.batch_size = 32\n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "#'/content/drive/MyDrive/Deep Learning Mini-Project/4_final_project/4_code/data/ETTh1_modified.csv'\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 6 # original 6\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "k_BCYODAwKl9"
   },
   "outputs": [],
   "source": [
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(' ','')\n",
    "    device_ids = args.devices.split(',')\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "53o3pZ809p-a"
   },
   "outputs": [],
   "source": [
    "# Set augments by using data name\n",
    "data_parser = {\n",
    "    #args.data:{'data':data.path, 'T':'OT', args.feature:[args.enc_in?, args.dec_in?, args.c_out?]}\n",
    "    'ETTh1':{'data':'ETTh1_modified.csv','T':'OT','M':[10,10,10],'S':[1,1,1],'MS':[10,10,1]},\n",
    "}\n",
    "if args.data in data_parser.keys():\n",
    "    data_info = data_parser[args.data]\n",
    "    args.data_path = data_info['data']\n",
    "    args.target = data_info['T']\n",
    "    args.enc_in, args.dec_in, args.c_out = data_info[args.features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yZ5Q2vyKwSfk"
   },
   "outputs": [],
   "source": [
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywY-umrw-mHO",
    "outputId": "005c231d-5faa-4eaf-e6bb-2f17c3530c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "{'model': 'informer', 'data': 'ETTh1', 'root_path': '/content/drive/MyDrive/DeepLearning/', 'data_path': 'ETTh1_modified.csv', 'features': 'M', 'target': 'OT', 'freq': 'h', 'checkpoints': './informer_checkpoints', 'seq_len': 96, 'label_len': 48, 'pred_len': 1080, 'enc_in': 10, 'dec_in': 10, 'c_out': 10, 'factor': 5, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'distil': True, 'output_attention': False, 'mix': True, 'padding': 0, 'batch_size': 32, 'learning_rate': 0.0001, 'loss': 'mse', 'lradj': 'type1', 'use_amp': False, 'num_workers': 0, 'itr': 1, 'train_epochs': 6, 'patience': 3, 'des': 'exp', 'use_gpu': True, 'gpu': 0, 'use_multi_gpu': False, 'devices': '0,1,2,3', 'detail_freq': 'h'}\n"
     ]
    }
   ],
   "source": [
    "print('Args in experiment:')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "KVHZhRB4-on9"
   },
   "outputs": [],
   "source": [
    "Exp = Exp_Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928tzaA2AA2g",
    "outputId": "76210bc6-66cc-4b27-ffce-389155455d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl1080_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7465\n",
      "val 1801\n",
      "test 1801\n",
      "\titers: 100, epoch: 1 | loss: 0.8097255\n",
      "\tspeed: 0.1934s/iter; left time: 251.2283s\n",
      "\titers: 200, epoch: 1 | loss: 0.8239695\n",
      "\tspeed: 0.1990s/iter; left time: 238.5647s\n",
      "Epoch: 1 cost time: 45.94141101837158\n",
      "Epoch: 1, Steps: 233 | Train Loss: 0.8920325 Vali Loss: 0.8442054 Test Loss: 0.7442928\n",
      "Validation loss decreased (inf --> 0.844205).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7168694\n",
      "\tspeed: 0.3722s/iter; left time: 396.8017s\n",
      "\titers: 200, epoch: 2 | loss: 0.7497817\n",
      "\tspeed: 0.1979s/iter; left time: 191.2068s\n",
      "Epoch: 2 cost time: 46.27942252159119\n",
      "Epoch: 2, Steps: 233 | Train Loss: 0.7567955 Vali Loss: 0.8587841 Test Loss: 0.7581216\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.7136365\n",
      "\tspeed: 0.3654s/iter; left time: 304.4121s\n",
      "\titers: 200, epoch: 3 | loss: 0.7825602\n",
      "\tspeed: 0.1996s/iter; left time: 146.3217s\n",
      "Epoch: 3 cost time: 46.36176514625549\n",
      "Epoch: 3, Steps: 233 | Train Loss: 0.6794802 Vali Loss: 0.8611084 Test Loss: 0.7889498\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.6778734\n",
      "\tspeed: 0.3688s/iter; left time: 221.3053s\n",
      "\titers: 200, epoch: 4 | loss: 0.6519580\n",
      "\tspeed: 0.1989s/iter; left time: 99.4516s\n",
      "Epoch: 4 cost time: 46.39665246009827\n",
      "Epoch: 4, Steps: 233 | Train Loss: 0.6411237 Vali Loss: 0.8873095 Test Loss: 0.8084890\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl1080_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1801\n",
      "test shape: (56, 32, 1080, 10) (56, 32, 1080, 10)\n",
      "test shape: (1792, 1080, 10) (1792, 1080, 10)\n",
      "mse:0.7440813779830933, mae:0.6142640709877014\n"
     ]
    }
   ],
   "source": [
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features,\n",
    "                args.seq_len, args.label_len, args.pred_len,\n",
    "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "\n",
    "    # train\n",
    "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "    exp.train(setting)\n",
    "\n",
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQi5-eLhviAR"
   },
   "source": [
    "##Test one more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7dvsjlUBXpE",
    "outputId": "8f111f2b-cdec-4cb4-c1ed-493a6511cce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>testing : informer_ETTh1_ftM_sl96_ll48_pl1080_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1801\n",
      "test shape: (56, 32, 1080, 10) (56, 32, 1080, 10)\n",
      "test shape: (1792, 1080, 10) (1792, 1080, 10)\n",
      "mse:0.7439651489257812, mae:0.614238440990448\n"
     ]
    }
   ],
   "source": [
    "    # test\n",
    "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "    exp.test(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SGga4BPyEq2"
   },
   "source": [
    "# Count the number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0cKsCAOlyEWl"
   },
   "outputs": [],
   "source": [
    "def count_model_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LkdvsJ0jyT8V",
    "outputId": "3f986ad7-6de3-4cd0-bdb8-026b07b37bf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "The model has 11340810 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "# Assuming args is an object with all necessary arguments for creating an Exp_Informer instance\n",
    "experiment = Exp_Informer(args)\n",
    "experiment._build_model()  # You need to ensure the model is built and assigned to self.model\n",
    "total_params = count_model_parameters(experiment.model)\n",
    "print(f\"The model has {total_params} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrbACuoKvx9X"
   },
   "source": [
    "# Saving prediction and true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7soDOS_BNB3",
    "outputId": "66e6a263-8417-46f6-d16f-48e7e0b816da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1792, 1080, 10), (1792, 1080, 10))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "preds = np.load('./results/'+setting+'/pred.npy')\n",
    "\n",
    "\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGYPIe26vgOA"
   },
   "source": [
    "##Draw graph on actual and predcition values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "N2SBBRpBGDHm",
    "outputId": "91073524-7ab1-49d3-e69f-c357b7191dae"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c525229b-51fb-4799-ae17-cbf47078aa45\", \"pred.csv\", 12663)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_9ade5dfe-dcf7-430d-b4c1-9fb881a33628\", \"true.csv\", 12282)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from google.colab import files\n",
    "\n",
    "# Convert numpy arrays to DataFrame\n",
    "# save only the last column (target feature)\n",
    "pred_df = pd.DataFrame(preds[0,:,-1])\n",
    "\n",
    "\n",
    "# Save as CSV files\n",
    "pred_csv_path = '/content/results/informer_ETTh1_ftM_sl96_ll48_pl1080_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0/pred.csv'\n",
    "pred_df.to_csv(pred_csv_path, index=False)\n",
    "\n",
    "\n",
    "# Trigger the downloads\n",
    "files.download(pred_csv_path)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
